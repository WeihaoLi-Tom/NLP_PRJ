{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2025 COMP90042 Project\n",
    "*Make sure you change the file name with your group id.*"
   ],
   "metadata": {
    "id": "32yCsRUo8H33"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:57:21.069745Z",
     "start_time": "2025-04-20T10:57:21.066683Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Readme\n",
    "*If there is something to be noted for the marker, please mention here.*\n",
    "\n",
    "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
   ],
   "metadata": {
    "id": "XCybYoGz8YWQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.DataSet Processing\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ],
   "metadata": {
    "id": "6po98qVA8bJD"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DATA COLLECTION"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# load data\n",
    "DATA_DIR = \"./data\"  \n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"train-claims.json\")\n",
    "DEV_FILE   = os.path.join(DATA_DIR, \"dev-claims.json\")\n",
    "TEST_FILE  = os.path.join(DATA_DIR, \"test-claims-unlabelled.json\")\n",
    "EVID_FILE  = os.path.join(DATA_DIR, \"evidence.json\")\n",
    "\n",
    "\n",
    "def load_claims(path, labelled=True):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        raw = json.load(f)\n",
    "    records = []\n",
    "    for cid, info in raw.items():\n",
    "        rec = {\n",
    "            \"claim_id\": cid,\n",
    "            \"claim_text\": info.get(\"claim_text\", \"\"),\n",
    "        }\n",
    "        if labelled:\n",
    "            rec[\"label\"] = info[\"claim_label\"]\n",
    "            rec[\"evid_ids\"] = info[\"evidences\"]\n",
    "        records.append(rec)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def load_evidence(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        raw = json.load(f)\n",
    "    return pd.DataFrame([{\"evid_id\": k, \"evid_text\": v} for k, v in raw.items()])\n",
    "\n",
    "# make them to dataframe\n",
    "df_train = load_claims(TRAIN_FILE, labelled=True)\n",
    "df_dev   = load_claims(DEV_FILE,   labelled=True)\n",
    "df_test  = load_claims(TEST_FILE,  labelled=False)\n",
    "df_evid  = load_evidence(EVID_FILE)\n",
    "\n",
    "# 4. have a look!\n",
    "print(\"Train size：\", len(df_train))\n",
    "print(\"Dev size：\", len(df_dev))\n",
    "print(\"Test  size：\", len(df_test))\n",
    "print(\"Evidence size：\", len(df_evid))\n",
    "\n",
    "\n",
    "display(df_train.head())\n",
    "display(df_evid.head())\n",
    "\n",
    "# 5. label count\n",
    "print(\"Train label distribution：\")\n",
    "display(df_train[\"label\"].value_counts())\n",
    "\n",
    "print(\"Dev label distribution：\")\n",
    "display(df_dev[\"label\"].value_counts())\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "qvff21Hv8zjk",
    "ExecuteTime": {
     "end_time": "2025-04-20T11:04:02.039176Z",
     "start_time": "2025-04-20T11:04:00.438934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size： 1228\n",
      "Dev size： 154\n",
      "Test  size： 153\n",
      "Evidence size： 1208827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     claim_id                                         claim_text  \\\n",
       "0  claim-1937  Not only is there no scientific evidence that ...   \n",
       "1   claim-126  El Niño drove record highs in global temperatu...   \n",
       "2  claim-2510             In 1946, PDO switched to a cool phase.   \n",
       "3  claim-2021  Weather Channel co-founder John Coleman provid...   \n",
       "4  claim-2449  \"January 2008 capped a 12 month period of glob...   \n",
       "\n",
       "             label                                           evid_ids  \n",
       "0         DISPUTED  [evidence-442946, evidence-1194317, evidence-1...  \n",
       "1          REFUTES                [evidence-338219, evidence-1127398]  \n",
       "2         SUPPORTS                 [evidence-530063, evidence-984887]  \n",
       "3         DISPUTED  [evidence-1177431, evidence-782448, evidence-5...  \n",
       "4  NOT_ENOUGH_INFO  [evidence-1010750, evidence-91661, evidence-72...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim_text</th>\n",
       "      <th>label</th>\n",
       "      <th>evid_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claim-1937</td>\n",
       "      <td>Not only is there no scientific evidence that ...</td>\n",
       "      <td>DISPUTED</td>\n",
       "      <td>[evidence-442946, evidence-1194317, evidence-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claim-126</td>\n",
       "      <td>El Niño drove record highs in global temperatu...</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>[evidence-338219, evidence-1127398]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claim-2510</td>\n",
       "      <td>In 1946, PDO switched to a cool phase.</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>[evidence-530063, evidence-984887]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claim-2021</td>\n",
       "      <td>Weather Channel co-founder John Coleman provid...</td>\n",
       "      <td>DISPUTED</td>\n",
       "      <td>[evidence-1177431, evidence-782448, evidence-5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claim-2449</td>\n",
       "      <td>\"January 2008 capped a 12 month period of glob...</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>[evidence-1010750, evidence-91661, evidence-72...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "      evid_id                                          evid_text\n",
       "0  evidence-0  John Bennet Lawes, English entrepreneur and ag...\n",
       "1  evidence-1  Lindberg began his professional career at the ...\n",
       "2  evidence-2  ``Boston (Ladies of Cambridge)'' by Vampire We...\n",
       "3  evidence-3  Gerald Francis Goyer (born October 20, 1936) w...\n",
       "4  evidence-4  He detected abnormalities of oxytocinergic fun..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evid_id</th>\n",
       "      <th>evid_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evidence-0</td>\n",
       "      <td>John Bennet Lawes, English entrepreneur and ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evidence-1</td>\n",
       "      <td>Lindberg began his professional career at the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evidence-2</td>\n",
       "      <td>``Boston (Ladies of Cambridge)'' by Vampire We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evidence-3</td>\n",
       "      <td>Gerald Francis Goyer (born October 20, 1936) w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evidence-4</td>\n",
       "      <td>He detected abnormalities of oxytocinergic fun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "SUPPORTS           519\n",
       "NOT_ENOUGH_INFO    386\n",
       "REFUTES            199\n",
       "DISPUTED           124\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev label distribution：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "SUPPORTS           68\n",
       "NOT_ENOUGH_INFO    41\n",
       "REFUTES            27\n",
       "DISPUTED           18\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TF-IDF"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:20:58.490610Z",
     "start_time": "2025-04-22T13:19:54.564140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "df_evid['processed_text'] = df_evid['evid_text'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "\n",
    "print(\"TF-IDF\")\n",
    "tfidf = TfidfVectorizer(max_features=50000, ngram_range=(1, 2))\n",
    "tfidf_matrix = tfidf.fit_transform(df_evid['processed_text'])\n",
    "print(f\"TF-IDF shape: {tfidf_matrix.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "TF-IDF shape: (1208827, 50000)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Model Implementation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ],
   "metadata": {
    "id": "1FA2ao2l8hOg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "    print(f\"Current GPU device: {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")"
   ],
   "metadata": {
    "id": "QIEqDDT78q39",
    "ExecuteTime": {
     "end_time": "2025-04-20T10:54:31.345309Z",
     "start_time": "2025-04-20T10:54:27.829687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4070 SUPER\n",
      "Current GPU device: 0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:36:52.870086Z",
     "start_time": "2025-04-22T13:24:53.709545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "!pip install -q sentence-transformers transformers\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "\n",
    "print(\"opensource model\")\n",
    "retriever = SentenceTransformer('paraphrase-mpnet-base-v2').to(device) \n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base') \n",
    "classifier = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=4).to(device)\n",
    "\n",
    "# label\n",
    "label_map = {0: \"SUPPORTS\", 1: \"REFUTES\", 2: \"NOT_ENOUGH_INFO\", 3: \"DISPUTED\"}\n",
    "label_to_id = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT_ENOUGH_INFO\": 2, \"DISPUTED\": 3}\n",
    "\n",
    "\n",
    "print(\"evidence embading\")\n",
    "batch_size = 1000\n",
    "all_embeddings = []\n",
    "for i in tqdm(range(0, len(df_evid), batch_size), desc=\"Encoding evidence\"):\n",
    "    batch = df_evid['processed_text'][i:i+batch_size].tolist()\n",
    "    embeddings = retriever.encode(batch, convert_to_tensor=True, show_progress_bar=False)\n",
    "    all_embeddings.append(embeddings)\n",
    "evidence_embeddings = torch.cat(all_embeddings)\n",
    "\n",
    "# 结合规则和模型\n",
    "def classify_with_rules_and_model(claim_text, evidence_texts):\n",
    "   \n",
    "    \n",
    "    if all(len(set(claim_text.lower().split()) & set(ev.lower().split())) < 3 for ev in evidence_texts):\n",
    "        return \"NOT_ENOUGH_INFO\"\n",
    "        \n",
    "   \n",
    "    combined_text = claim_text + tokenizer.sep_token + tokenizer.sep_token.join(evidence_texts)\n",
    "    inputs = tokenizer(combined_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = classifier(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    \n",
    "    if probs[label_to_id[\"DISPUTED\"]] > 0.2 or (max(probs) - min(probs) < 0.3):\n",
    "        has_contradiction = any(\"contrary\" in ev.lower() or \"oppose\" in ev.lower() or \n",
    "                              \"disagree\" in ev.lower() or \"conflict\" in ev.lower() for ev in evidence_texts)\n",
    "        if has_contradiction:\n",
    "            return \"DISPUTED\"\n",
    "    \n",
    "    return label_map[predicted_class]\n",
    "\n",
    "\n",
    "def retrieve_evidence(claim_text, top_k=5, top_tfidf=20):\n",
    "    \n",
    "    \n",
    "    claim_embedding = retriever.encode(claim_text, convert_to_tensor=True)\n",
    "    cos_scores = util.cos_sim(claim_embedding, evidence_embeddings)[0]\n",
    "    \n",
    " \n",
    "    claim_tfidf = tfidf.transform([preprocess_text(claim_text)])\n",
    "    tfidf_scores = np.array((claim_tfidf @ tfidf_matrix.T).toarray()[0])\n",
    "    \n",
    "\n",
    "    tfidf_top_indices = np.argsort(-tfidf_scores)[:top_tfidf]\n",
    "    \n",
    "\n",
    "    semantic_scores = cos_scores.cpu().numpy()\n",
    "    \n",
    "\n",
    "    for idx in tfidf_top_indices:\n",
    "        semantic_scores[idx] += 0.2  # 提升TF-IDF匹配较好的文档的分数\n",
    "    \n",
    "    # 获取最终的前K个结果\n",
    "    final_top_indices = np.argsort(-semantic_scores)[:top_k]\n",
    "    evidence_ids = df_evid.iloc[final_top_indices]['evid_id'].tolist()\n",
    "    evidence_texts = df_evid.iloc[final_top_indices]['processed_text'].tolist()\n",
    "    \n",
    "    return evidence_ids, evidence_texts"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "opensource model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evidence embading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding evidence: 100%|██████████| 1209/1209 [11:53<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T12:44:38.732681Z",
     "start_time": "2025-04-22T12:44:38.724434Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:39:39.002726Z",
     "start_time": "2025-04-22T13:37:49.493843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"generate result\")\n",
    "results = {}\n",
    "for idx, row in tqdm(df_dev.iterrows(), total=len(df_dev), desc=\"Processing claims\"):\n",
    "    claim_id = row['claim_id']\n",
    "    claim_text = row['claim_text']\n",
    "    \n",
    "    \n",
    "    evidence_ids, evidence_texts = retrieve_evidence(claim_text, top_k=5)\n",
    "    \n",
    "    \n",
    "    label = classify_with_rules_and_model(claim_text, evidence_texts)\n",
    "    \n",
    "    \n",
    "    results[claim_id] = {\n",
    "        \"claim_label\": label,\n",
    "        \"evidences\": evidence_ids\n",
    "    }\n",
    "\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "\n",
    "output_path = os.path.join(DATA_DIR, 'dev-predictions.json')\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"saved into {output_path}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claims: 100%|██████████| 154/154 [01:49<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved into ./data\\dev-predictions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.Testing and Evaluation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ],
   "metadata": {
    "id": "EzGuzHPE87Ya"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "6ZVeNYIH9IaL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Object Oriented Programming codes here\n",
    "\n",
    "*You can use multiple code snippets. Just add more if needed*"
   ],
   "metadata": {
    "id": "mefSOe8eTmGP"
   }
  }
 ]
}
